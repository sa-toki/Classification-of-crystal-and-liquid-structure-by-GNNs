{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4704b7",
   "metadata": {},
   "source": [
    "# Package Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install numpy\n",
    "conda install -c conda-forge matplotlib\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44a844",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd15ee6",
   "metadata": {},
   "source": [
    "# Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "TEMP=269\n",
    "np.random.seed(seed )\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0e524",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60df874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \n",
    "    def __init__(self, choiced_particle_num=3):\n",
    "        h_ice_ox_data = np.load('./ice/{}K_ice_data/1h_ice_oxygen.npy'.format(TEMP))\n",
    "        h_ice_h1_data= np.load('./ice/{}K_ice_data/1h_ice_hydrogen1.npy'.format(TEMP))\n",
    "        h_ice_h2_data= np.load('./ice/{}K_ice_data/1h_ice_hydrogen2.npy'.format(TEMP))\n",
    "        h_ice_box = np.load('./ice/{}K_ice_data/1h_ice_box.npy'.format(TEMP))\n",
    "        c_ice_ox_data = np.load('./ice/{}K_ice_data/1c_ice_oxygen.npy'.format(TEMP))\n",
    "        c_ice_h1_data= np.load('./ice/{}K_ice_data/1c_ice_hydrogen1.npy'.format(TEMP))\n",
    "        c_ice_h2_data= np.load('./ice/{}K_ice_data/1c_ice_hydrogen2.npy'.format(TEMP))\n",
    "        c_ice_box = np.load('./ice/{}K_ice_data/1c_ice_box.npy'.format(TEMP))\n",
    "        wat_ox_data = np.load('./wat/{}K_wat_data/water_oxygen.npy'.format(TEMP))\n",
    "        wat_h1_data = np.load('./wat/{}K_wat_data/water_hydrogen1.npy'.format(TEMP))\n",
    "        wat_h2_data = np.load('./wat/{}K_wat_data/water_hydrogen2.npy'.format(TEMP))\n",
    "        wat_box = np.load('./wat/{}K_wat_data/water_box.npy'.format(TEMP))\n",
    "        \n",
    "        h_ice_data=np.stack([h_ice_h1_data,h_ice_h2_data,h_ice_ox_data],2)\n",
    "        c_ice_data=np.stack([c_ice_h1_data,c_ice_h2_data,c_ice_ox_data],2)\n",
    "        wat_data=np.stack([wat_h1_data,wat_h2_data,wat_ox_data],2)\n",
    "        \n",
    "        h_ice_label=np.zeros_like(h_ice_data[:,0,0,0])\n",
    "        c_ice_label=np.ones_like(c_ice_data[:,0,0,0])\n",
    "        wat_label=np.full_like(wat_data[:,0,0,0],2)\n",
    "        \n",
    "        self.choiced_particle_num = choiced_particle_num#選択粒子数\n",
    "        self.data_size = h_ice_data.shape[0] +c_ice_data.shape[0]+wat_data.shape[0]\n",
    "        self.maxlength=1.5*0.31668\n",
    "        \n",
    "        #print(h_ice_data.shape)\n",
    "        #print(c_ice_data.shape)\n",
    "        \n",
    "        x=[]\n",
    "        for i in range(h_ice_data.shape[0]):\n",
    "            x.append(h_ice_data[i])#[スナップショット，粒子，座標]\n",
    "        for i in range(c_ice_data.shape[0]):\n",
    "            x.append(c_ice_data[i])\n",
    "        for i in range(wat_data.shape[0]):\n",
    "            x.append(wat_data[i])\n",
    "            \n",
    "        label = np.concatenate([h_ice_label, c_ice_label,wat_label],0)\n",
    "        box = np.concatenate([h_ice_box, c_ice_box,wat_box],0)\n",
    "        \n",
    "        \n",
    "        self.x_train, self.x_test, self.label_train, self.label_test, self.box_train, self.box_test = self.train_test_split(x, label, box, test_size=0.2)\n",
    "        self.x_train, self.x_val, self.label_train, self.label_val, self.box_train, self.box_val = self.train_test_split(self.x_train, self.label_train, self.box_train, test_size=0.2)\n",
    "        \n",
    "        print(len(self.x_train),self.x_train[0].shape)\n",
    "        print(len(self.x_test),self.x_test[0].shape)\n",
    "        print(len(self.x_val),self.x_val[0].shape)\n",
    "    def train_test_split(self,x,label,box,test_size=0.2):\n",
    "        data_size=len(x)\n",
    "        test_batch=int(len(x)*test_size)\n",
    "        test_index=np.sort(np.random.choice(data_size,test_batch,replace=False))\n",
    "        train_index=np.delete(np.array([i for i in range(len(x))]),test_index)\n",
    "        x_test=[x[i].copy() for i in test_index]\n",
    "        x_train=[x[i].copy() for i in train_index]\n",
    "        label_test=label[test_index]\n",
    "        label_train=label[train_index]\n",
    "        box_test=box[test_index]\n",
    "        box_train=box[train_index]\n",
    "        return x_train,x_test,label_train,label_test,box_train,box_test\n",
    "    \n",
    "    \n",
    "    def get_train_batch(self, batch_size):\n",
    "        return self._get_batch(batch_size, self.x_train, self.label_train, self.box_train)\n",
    "    \n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        return self._get_batch(batch_size, self.x_test, self.label_test, self.box_test)\n",
    "    \n",
    "    \n",
    "    def get_val_batch(self, batch_size):\n",
    "        return self._get_batch(batch_size, self.x_val, self.label_val, self.box_val)\n",
    "    \n",
    "    \n",
    "    def _get_batch(self, batch_size, x, label, box):\n",
    "        batch_idx = np.random.randint(0,len(x), batch_size)#batch_size個のランダムな配列番号\n",
    "        batch_x = [x[i].copy() for i  in batch_idx]\n",
    "        batch_label, batch_box = label[batch_idx], box[batch_idx]\n",
    "        batch_x, batch_label = self._choice_particle(batch_x.copy(), batch_label, batch_box)\n",
    "        return batch_x, batch_label\n",
    "    \n",
    "    \n",
    "    def _choice_particle(self, x, label, box):\n",
    "        x=x.copy()\n",
    "        choiced_x = np.zeros((len(x), self.choiced_particle_num, x[0].shape[1], x[0].shape[2]))\n",
    "        for i in range(len(x)):#各スナップショット分繰り返す\n",
    "            center_particle_idx = np.random.randint(0, x[i].shape[0])\n",
    "            dx = x[i][ :, 2, 0:3] - x[i][center_particle_idx, 2, 0:3]\n",
    "            for coordinate in range(3):#center_particleを中心にする\n",
    "                l1 = np.where(dx[:,  coordinate] > box[i, coordinate]/2, -box[i, coordinate], 0)\n",
    "                l2 = np.where(dx[:,  coordinate] < -box[i, coordinate]/2, +box[i, coordinate], 0)\n",
    "                x[i][ :, 0, coordinate] = x[i][ :, 0, coordinate] + l1 + l2\n",
    "                x[i][ :, 1, coordinate] = x[i][ :, 1, coordinate] + l1 + l2\n",
    "                x[i][ :, 2, coordinate] = x[i][ :, 2, coordinate] + l1 + l2\n",
    "            d = np.linalg.norm(x[i][ :, 2,0:3] - x[i][center_particle_idx, 2, 0:3], axis = 1)\n",
    "            arg = np.argsort(d)[:self.choiced_particle_num]#距離の近い順に並べてchoiced_particle_num個持ってくる\n",
    "            choiced_x[i, :, :, :] = x[i][arg, :, :].copy()\n",
    "            reshaped_x=np.concatenate([choiced_x[:,:,0,:],choiced_x[:,:,1,:],choiced_x[:,:,2,:]],1)\n",
    "        return reshaped_x, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e4012",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833708f",
   "metadata": {},
   "source": [
    "### We used TeaNet as our model; the implementation of TeaNet can be found in the paper [1].The input to TeaNet is three-dimensional coordinate data, the form is (batch size, number of particles, 3), and the output is a predicted scalar value (batch size, 1).\n",
    "\n",
    "[1]Takamoto, S.; Izumi, S.; Li, J. TeaNet: Universal neural network interatomic potential\n",
    "inspired by iterative electronic relaxations. Comput. Mater. Sci. 2022, 207, 111280. https://doi.org/10.1016/j.commatsci.2022.111280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeaNet(nn.Module):\n",
    "    def __init__(self,batch_size,molecule_num,particle_num):\n",
    "        super(TeaNet,self).__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.molecule_num=molecule_num\n",
    "        self.particle_num=particle_num\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd96db8",
   "metadata": {},
   "source": [
    "# Learning Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62837726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(batch_size, molecule_num):   \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU\",torch.cuda.is_available())\n",
    "        device=torch.device(\"cuda\")\n",
    "        print(device)\n",
    "    \n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    iters_num = 400000 + 5\n",
    "    delta = 1e-7\n",
    "    \n",
    "    dataloader = DataLoader(choiced_particle_num=molecule_num)\n",
    "    \n",
    "    x_val, label_val = dataloader.get_val_batch(batch_size)\n",
    "    x_val = torch.from_numpy(x_val).to(torch.float32).to(device)\n",
    "    label_val = torch.from_numpy(label_val).to(torch.long).to(device)\n",
    "    \n",
    "    particle_num=x_val.shape[1]\n",
    "    \n",
    "    net = TeaNet(batch_size,molecule_num,particle_num).to(device) \n",
    "    #print(net)\n",
    "    #print(list(net.parameters()))\n",
    "    loss_list_train = []\n",
    "    accuracy_list_train = []       \n",
    "    loss_list_val = []\n",
    "    accuracy_list_val = []\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    optimizer = torch.optim.RMSprop(net.parameters(), lr=learning_rate)\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=int(100000),gamma=0.5)\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    softmax=nn.Softmax(dim=1)\n",
    "    \n",
    "    for itr in range(iters_num+1):\n",
    "        x_batch, label_batch = dataloader.get_train_batch(batch_size)\n",
    "        x_batch = torch.from_numpy(x_batch).to(torch.float32).to(device)\n",
    "        label_batch = torch.from_numpy(label_batch).to(torch.long).to(device)\n",
    "        \n",
    "        \n",
    "        net.train()\n",
    "        y_pred=net(x_batch)\n",
    "        loss_value_train=loss(y_pred,label_batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred=softmax(y_pred)\n",
    "            _,y_pred=torch.max(y_pred ,1)\n",
    "            correct_prediction_train = torch.eq(y_pred, label_batch).to(torch.float32)\n",
    "            accuracy_value_train = torch.mean(correct_prediction_train.to(torch.float32))\n",
    "            \n",
    "            loss_list_train.append(loss_value_train.detach().cpu().numpy().copy())\n",
    "            accuracy_list_train.append(accuracy_value_train.detach().cpu().numpy().copy())\n",
    "            print('Loss {}: {}'.format(itr+1,loss_value_train))\n",
    "            print('Accuracy{} : {}'.format(itr+1,accuracy_value_train))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_value_train.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if itr % 100 == 0 and itr != 0:\n",
    "                net.eval()\n",
    "                y_val=net(x_val)\n",
    "                loss_value_val=loss(y_val,label_val)\n",
    "                \n",
    "                y_val=softmax(y_val)\n",
    "                _,y_val=torch.max(y_val ,1)\n",
    "                correct_prediction_val = torch.eq(y_val, label_val).to(torch.float32)\n",
    "                accuracy_value_val=torch.mean(correct_prediction_val)\n",
    "                loss_list_val.append(loss_value_val.detach().cpu().numpy().copy())\n",
    "                accuracy_list_val.append(accuracy_value_val.detach().cpu().numpy().copy())\n",
    "                print('TestAccuracy{} : {}'.format(itr+1,accuracy_value_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf0019",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =512\n",
    "for particle_num in [3,5,7,9]:\n",
    "    print(particle_num)\n",
    "    main(batch_size,particle_num)\n",
    "    clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
